{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hourglass Pose Estimation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTWe_iYhZYRg"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Layer, Flatten, Conv2D, MaxPool2D, UpSampling2D, Add, ReLU, BatchNormalization\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.backend import shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl6dZ9CiyCbE"
      },
      "source": [
        "class Residual(Layer):\n",
        "  def __init__(self, input_shape, output_shape):\n",
        "    super(Residual, self).__init__()    \n",
        "    self.conv1 = Conv2D(int(output_shape/2), kernel_size=(1,1), strides=(1,1),padding='same')\n",
        "    self.conv2 = Conv2D(int(output_shape/2), kernel_size=(3,3), strides=(1,1),padding='same')\n",
        "    self.conv3 = Conv2D(output_shape, kernel_size=(1,1), strides=(1,1),padding='same')\n",
        "    self.relu = ReLU()\n",
        "    self.bn1 = BatchNormalization()\n",
        "    self.bn2 = BatchNormalization()\n",
        "    self.bn3 = BatchNormalization()\n",
        "    self.identity = Conv2D(output_shape, kernel_size=(1,1), strides=(1,1), padding='same')\n",
        "\n",
        "    if input_shape == output_shape:\n",
        "      self.need_skip = False\n",
        "    else:\n",
        "      self.need_skip = True\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if self.need_skip:\n",
        "      res = self.identity(inputs)\n",
        "    else:\n",
        "      res = inputs\n",
        "    # print(\"input\", (inputs))\n",
        "    x = self.bn1(inputs)\n",
        "    # print(\"after bn 1\", (x))\n",
        "    x = self.relu(x)\n",
        "    y = self.conv1(x)\n",
        "    # print(\"after conv1\", (y))\n",
        "    x = self.bn2(y)\n",
        "    # print(\"after bn2\", x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn3(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv3(x)\n",
        "    x += res\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VP9barNyH4Q"
      },
      "source": [
        "# recursive hourglass\n",
        "class Hourglass(Layer):\n",
        "  def __init__(self, n, filter_size):\n",
        "    super(Hourglass, self).__init__()\n",
        "    self.l1 = Residual(filter_size, filter_size)\n",
        "    self.m = MaxPool2D(pool_size=(2, 2))\n",
        "    self.l2 = Residual(filter_size, filter_size)\n",
        "\n",
        "    self.n = n\n",
        "\n",
        "    # Recursive hourglass\n",
        "    if self.n > 1:\n",
        "        self.l3 = Hourglass(n-1, filter_size)\n",
        "    else:\n",
        "        self.l3 = Residual(filter_size, filter_size)\n",
        "    self.l4 = Residual(filter_size, filter_size)\n",
        "    self.up = UpSampling2D(size=(2,2))\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    l1 = self.l1(inputs)\n",
        "    x = self.m(inputs)\n",
        "    x = self.l2(x)\n",
        "    x = self.l3(x)\n",
        "    x = self.l4(x)\n",
        "    up = self.up(x)\n",
        "    return l1 + up"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2pc1oK0Pb3V"
      },
      "source": [
        "def heatmap_loss_function(y_actual, y_predicted):\n",
        "  l = (y_predicted-y_actual)**2\n",
        "  l = l.mean(dim=3).mean(dim=2).mean(dim=1)\n",
        "  return l ## l of dim bsize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oAp1qTz2UMd"
      },
      "source": [
        "def combined_loss_function(hm_gt, hm):\n",
        "  num_hourglasses = 4\n",
        "        #   combined_loss = []\n",
        "        # for i in range(self.nstack):\n",
        "        #     combined_loss.append(self.heatmapLoss(combined_hm_preds[0][:,i], heatmaps))\n",
        "        # combined_loss = torch.stack(combined_loss, dim=1)\n",
        "        # return combined_loss\n",
        "\n",
        "  combined_loss = []\n",
        "  for i in range(num_hourglasses):\n",
        "    combined_loss.append(heatmap_loss_function(hm[0][:,i], hm_gt))\n",
        "  combined_loss = tf.keras.backend.stack(combined_loss, axis=1)\n",
        "  return combined_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihwgr-fIwUTY"
      },
      "source": [
        "class Features(Layer):\n",
        "  def __init__(self, input_shape):\n",
        "    super(Features, self).__init__()\n",
        "    self.l1 = Residual(input_shape, input_shape)\n",
        "    self.c1 = Conv2D(input_shape, kernel_size=(1,1), strides=(1,1), padding='same')\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x = self.l1(inputs)\n",
        "    x = self.c1(x)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHdLde1Fihqw"
      },
      "source": [
        "def PoseEstimationModel(num_hourglasses=4):\n",
        "  inputs = Input(shape=(256, 256, 3))\n",
        "\n",
        "  # initial processing - could put this into Sequential?\n",
        "  x = Conv2D(64, kernel_size = (7,7), strides=(2, 2), padding='same', activation='relu')(inputs)\n",
        "  x = Residual(64, 128)(x)\n",
        "  x = MaxPool2D(pool_size=(2,2))(x)\n",
        "  x = Residual(128, 128)(x)\n",
        "  x = Residual(128, 256)(x)\n",
        "  features = [Features(256) for i in range(num_hourglasses)]\n",
        "  outs = [Conv2D(256, kernel_size = (1,1), strides = (1,1), padding = 'same') for i in range(num_hourglasses)]\n",
        "  merge_features =  [Conv2D(256, kernel_size = (1,1), strides = (1,1), padding = 'same') for i in range(num_hourglasses-1)]\n",
        "  merge_predictions =  [Conv2D(256, kernel_size = (1,1), strides = (1,1), padding = 'same') for i in range(num_hourglasses-1)]\n",
        "\n",
        "  combined_heatmap_predictions = []\n",
        "\n",
        "  for i in range(num_hourglasses):\n",
        "    h = Hourglass(n=4, filter_size=256)(x)\n",
        "    # add intermediate predictions\n",
        "    f = features[i](h)\n",
        "    prediction = outs[i](f)\n",
        "    combined_heatmap_predictions.append(prediction)\n",
        "    if i < num_hourglasses - 1:\n",
        "      x = x + merge_features[i](f) + merge_predictions[i](prediction)\n",
        "  output = tf.keras.backend.stack(combined_heatmap_predictions, axis=1)\n",
        "    \n",
        "  model = Model(inputs, output)\n",
        "\n",
        "  model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='combined_loss_function',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXM7xY0Xl63B"
      },
      "source": [
        "pem = PoseEstimationModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTm6ZD2nmE66"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6xpMJL64GGo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}